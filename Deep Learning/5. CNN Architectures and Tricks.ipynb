{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Architectures\n",
    "\n",
    "## 1. LeNet\n",
    "\n",
    "- Tool into consideration <mark>**Input Invariance**</mark> (rotated, different bold levels, etc.)\n",
    "- Problem with establising **relationship between objects**\n",
    "\n",
    "<img src=\"images/Screenshot 2023-10-25 at 6.41.47 PM.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeCun, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(5 * 5 * 16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 5 * 5 * 16)\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 2. AlexNet (UofT)\n",
    "\n",
    "- Larger training dataset (from ImageNet)\n",
    "- Increase in compute power\n",
    "- **Larger model size/more layers**\n",
    "\n",
    "Also application of tricks to increase accuracy\n",
    "\n",
    "- Deeper model (large number of convolutional layers)\n",
    "- Use ReLU activation functions instead of sigmoids\n",
    "- Dropout, <mark>**data augmentation**</mark> - random transformation with noise to data (crop and resize, flip, color distord, rotate, etc.)\n",
    "\n",
    "PROBLEM:\n",
    "\n",
    "- Training deep models often failed due to <mark>**vanishing or exploding gradients**</mark>\n",
    "\n",
    "<img src=\"images/Screenshot 2023-10-25 at 6.51.32 PM.png\" height=70% width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3. GoogLeNet\n",
    "\n",
    "Go deeper, much more parameter efficient\n",
    "\n",
    "<img src=\"images/Screenshot 2023-10-25 at 6.54.34 PM.png\" height=70% width=70%>\n",
    "\n",
    "### **Inception Block**\n",
    "\n",
    "- Used a mixture of 3x3, 5x5, 7x7 filters on one layer, and then **concatenate** the results\n",
    "- Can mostly use 3x3 layers\n",
    "\n",
    "#### *VGG (Visual Geometry Group) research*\n",
    "\n",
    "- Found out that we only need 3x3 filters. Stacked 3x3 filters can approximate **any** larger-sized convolution, more efficiently\n",
    "\n",
    "<img src=\"images/Screenshot 2023-10-25 at 6.56.37 PM.png\" height=50% width=50%>\n",
    "\n",
    "### **Pointwise convolution** (3x1x1 kernels)\n",
    "\n",
    "Realize that the kernel always reduce output depth to 1, so we **only have 3 parameters to learn**\n",
    "\n",
    "Also, reducing depth of an input, so next layer have less parameters\n",
    "\n",
    "### **Auxilary Loss**\n",
    "\n",
    "- Intermediate classifiers to calculate loss function in intermediate layers. Final loss is a combination of the intermediate losses and the final loss\n",
    "- Forces the model to also perform well in intermediate layers\n",
    "- Avoid gradient vanishing problem\n",
    "\n",
    "<img src=\"images/Screenshot 2023-10-25 at 7.00.12 PM.png\" height=50% width=50%>\n",
    "\n",
    "### **Residual Networks**\n",
    "\n",
    "Uses **skip connections** to provide deeper layers more direct access to signals, which otherwise be lost to vanishing gradients\n",
    "\n",
    "Basically ensure that IF the gradient is 0 there is still a non-zero input from the first input layer\n",
    "\n",
    "<img src=\"images/Screenshot 2023-10-25 at 7.03.45 PM.png\" height=50% width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4. ResNets (Residual Networks)\n",
    "\n",
    "Applying the idea of skipping connections:\n",
    "\n",
    "<img src=\"images/Screenshot 2023-10-25 at 9.38.33 PM.png\" height=70% width=70%>\n",
    "\n",
    "NOTE:\n",
    "\n",
    "- Downsampling using stride 2 instead of max/avg pooling\n",
    "- Apply **global average pooling** in last layer, meaning that from 512x5x5, avg pooling is applied on each 5x5, and generate **512x5x5 scalar flattenned values**\n",
    "- Also, only a **single fully-connected classification** layer is needed, since the learned embeddings are already so strong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "## 5. Transfer Learning\n",
    "\n",
    "Apparently, the entire Convolutional part of the network (encoder) that is before the Classification part generates something called **embedding**\n",
    "\n",
    "This embedding is a learned, succinct representation of input image. CNNs learn something general about representing images!\n",
    "\n",
    "This can then a fed into various classification layers for different appliations! (so we don't have to reinvent the cycle and train the CNN layers again)\n",
    "\n",
    "<img src=\"images/Screenshot 2023-10-25 at 9.46.09 PM.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
