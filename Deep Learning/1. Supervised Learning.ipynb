{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories of Machine Learning\n",
    "\n",
    "### 1. Supervised Learning\n",
    "\n",
    "Providing the model with **pairs of input and expected outputs**\n",
    "\n",
    "- Regression (output is real-valued or continuous value) or Classification (output is categorical or 1 of N)\n",
    "- Requires data with ground-truth labels/outputs\n",
    "\n",
    "### 2. Unsupervised Learning\n",
    "\n",
    "Tell the model: Start reading all the data, and predict the next word by yourself (language models)  \n",
    "Provide the model with data, without showing it the output (without any goals)\n",
    "--> Once it \"learns\" knowledge, starts to ask information\n",
    "\n",
    "- Self-supervised Learning, Semi-supervised Learning\n",
    "- Requires observations without human annotations\n",
    "\n",
    "### 3. Reinforcement Learning (CSC413)\n",
    "\n",
    "The model will explore by itself, and then based on the feedback we give them, it will \"learn\" and try to improve the chance of winning\n",
    "\n",
    "- Sparse rewards from environment (e.g., won/lost)\n",
    "- Actions affects the environment (dynamic nature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Supervised Learning\n",
    "\n",
    "Input -> Output (X, y)\n",
    "\n",
    "- **quantify model performance** --> minimum error --> we want to minimize this\n",
    "\n",
    "EXAMPLE: Regression (fitting a polynomial)  \n",
    "\n",
    "Data: blue, Green: solution, Red: prediction\n",
    "\n",
    "![Alt text](images/img2.png)\n",
    "\n",
    "##### *Which one is fitting the data better?*\n",
    "\n",
    "We call 1 and 2 \"<mark>**under fitting**</mark>\", the model is so simple that we cannot make the model learn by itself (high bias)  \n",
    "\n",
    "We call 4 \"<mark>**overfitting**</mark>\" --> even though currently low error, adding other points will have huge error  \n",
    "  The model has too many degrees of freedom\n",
    "\n",
    "3 is good, depending on **<mark>generalization</mark>**. If we add a new point, 3 will give the least error  \n",
    "  Fair amount of bias  \n",
    "  Fair amount of variance  \n",
    "\n",
    "We have restricted the model by such strong bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good assumptions are essential\n",
    "\n",
    "**<mark>Inductive bias</mark>** is the set of assumptions that are made by user (prior knowledge inserted into the model) --> used for modelling\n",
    "\n",
    "**No free lunch theorem** If we don't take any inductive bias into the model, all models will behave badly, the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalization, Overfitting, and Underfitting\n",
    "\n",
    "ML is a game of balance, with our objective being to **generalize as well as possible to future data**, not just learning the training data\n",
    "\n",
    "#### Bias vs Variance Tradeoff\n",
    "- Greater model complexity higher variance and chance of over-fitting\n",
    "- Lower model complexity leads to higher bias and under-fitting\n",
    "\n",
    "##### We have to evaluate the model with **untrained data**\n",
    "\n",
    "![Alt text](images/image3.png)\n",
    "\n",
    "(Green line is error compared to trained data, Red line is error generated by untrained data (new points input --> This is more generalized))  \n",
    "--> We will try to pick the point that has the smallest difference between error by trained data and untrainted data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Data (BAD)\n",
    "\n",
    "More data --> better model\n",
    "\n",
    "However, we can't use all out data for training, need to use some to test our model!\n",
    "\n",
    "Typically split our data into training and test data\n",
    "\n",
    "**You can also overfit to your test data**\n",
    "\n",
    "--> <mark>The model will implicitly optimize towards testing data (WRONG)</mark>\n",
    "\n",
    "![Alt text](images/image.png)\n",
    "\n",
    "### Validation and Holdout Data\n",
    "\n",
    "Also typical to split our data into training, test and validation  \n",
    "\n",
    "> Train on training, tune hyper-parameters on validation, evaluate sparingly on test set (holdout data)  \n",
    "\n",
    "Ideally use the holdout data only once, but in practice this is not likely  \n",
    "\n",
    "--> Randomly split the dataset  \n",
    "--> But should be the same distribution between chunks (all 40% cat, 60% dog)\n",
    "\n",
    "Choosing model and train with (<mark>Training and Validation</mark>) --> Then, we use <mark>Testing data</mark> that we don't have access to (don't look at it) to generate a report\n",
    "\n",
    "![Alt text](images/image-1.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
